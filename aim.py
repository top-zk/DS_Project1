import numpy as np
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score, classification_report
import warnings

warnings.filterwarnings('ignore')


class MLHelper:
    def __init__(self):
        self.numpy_functions = {
            'array_creation': self.numpy_array_creation,
            'array_operations': self.numpy_array_operations,
            'indexing_slicing': self.numpy_indexing_slicing,
            'linear_algebra': self.numpy_linear_algebra,
            'statistics': self.numpy_statistics
        }

        self.sklearn_functions = {
            'data_loading': self.sklearn_data_loading,
            'preprocessing': self.sklearn_preprocessing,
            'train_test_split': self.sklearn_train_test_split,
            'classification': self.sklearn_classification,
            'clustering': self.sklearn_clustering
        }

    def help(self, topic=None):
        """ä¸»å¸®åŠ©å‡½æ•°"""
        if topic is None:
            self.show_all_topics()
        elif topic.startswith('numpy'):
            self.handle_numpy_query(topic)
        elif topic.startswith('sklearn'):
            self.handle_sklearn_query(topic)
        else:
            print("è¯·æŒ‡å®š'numpy'æˆ–'sklearn'ä¸»é¢˜")

    def show_all_topics(self):
        """æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨ä¸»é¢˜"""
        print("=" * 50)
        print("NumPy ä¸»é¢˜:")
        print("=" * 50)
        for key in self.numpy_functions.keys():
            print(f"- numpy_{key}")

        print("\n" + "=" * 50)
        print("Scikit-learn ä¸»é¢˜:")
        print("=" * 50)
        for key in self.sklearn_functions.keys():
            print(f"- sklearn_{key}")

        print("\nä½¿ç”¨æ–¹å¼: helper.help('numpy_array_creation')")

    def handle_numpy_query(self, topic):
        """å¤„ç†NumPyæŸ¥è¯¢"""
        topic_key = topic.replace('numpy_', '')
        if topic_key in self.numpy_functions:
            self.numpy_functions[topic_key]()
        else:
            print(f"æœªæ‰¾åˆ°ä¸»é¢˜: {topic}")
            print("å¯ç”¨çš„NumPyä¸»é¢˜:")
            for key in self.numpy_functions.keys():
                print(f"- numpy_{key}")

    def handle_sklearn_query(self, topic):
        """å¤„ç†Scikit-learnæŸ¥è¯¢"""
        topic_key = topic.replace('sklearn_', '')
        if topic_key in self.sklearn_functions:
            self.sklearn_functions[topic_key]()
        else:
            print(f"æœªæ‰¾åˆ°ä¸»é¢˜: {topic}")
            print("å¯ç”¨çš„Scikit-learnä¸»é¢˜:")
            for key in self.sklearn_functions.keys():
                print(f"- sklearn_{key}")

    # ===== NumPy å‡½æ•° =====
    def numpy_array_creation(self):
        """NumPyæ•°ç»„åˆ›å»º"""
        print("=" * 60)
        print("NumPy æ•°ç»„åˆ›å»ºæ–¹æ³•")
        print("=" * 60)

        # ä»åˆ—è¡¨åˆ›å»º
        print("1. ä»åˆ—è¡¨åˆ›å»ºæ•°ç»„:")
        list_data = [1, 2, 3, 4, 5]
        arr_from_list = np.array(list_data)
        print(f"   np.array({list_data}) = {arr_from_list}")
        print(f"   å½¢çŠ¶: {arr_from_list.shape}, æ•°æ®ç±»å‹: {arr_from_list.dtype}")

        # åˆ›å»ºç‰¹æ®Šæ•°ç»„
        print("\n2. åˆ›å»ºç‰¹æ®Šæ•°ç»„:")
        zeros_arr = np.zeros((2, 3))
        ones_arr = np.ones((2, 2))
        range_arr = np.arange(0, 10, 2)
        print(f"   np.zeros((2, 3)):\n{zeros_arr}")
        print(f"   np.ones((2, 2)):\n{ones_arr}")
        print(f"   np.arange(0, 10, 2): {range_arr}")

        # éšæœºæ•°ç»„
        print("\n3. éšæœºæ•°ç»„:")
        random_arr = np.random.rand(3, 2)
        print(f"   np.random.rand(3, 2):\n{random_arr}")

    def numpy_array_operations(self):
        """NumPyæ•°ç»„æ“ä½œ"""
        print("=" * 60)
        print("NumPy æ•°ç»„æ“ä½œ")
        print("=" * 60)

        # åˆ›å»ºç¤ºä¾‹æ•°ç»„
        arr1 = np.array([[1, 2, 3], [4, 5, 6]])
        arr2 = np.array([[2, 2, 2], [1, 1, 1]])

        print("ç¤ºä¾‹æ•°ç»„:")
        print(f"arr1:\n{arr1}")
        print(f"arr2:\n{arr2}")

        # æ•°å­¦è¿ç®—
        print("\n1. æ•°å­¦è¿ç®—:")
        print(f"åŠ æ³•: arr1 + arr2 =\n{arr1 + arr2}")
        print(f"ä¹˜æ³•: arr1 * 2 =\n{arr1 * 2}")
        print(f"çŸ©é˜µä¹˜æ³• (dot): {np.dot([1, 2, 3], [4, 5, 6])}")

        # æ•°ç»„æ–¹æ³•
        print("\n2. æ•°ç»„æ–¹æ³•:")
        print(f"å½¢çŠ¶é‡å¡‘: arr1.reshape(3, 2) =\n{arr1.reshape(3, 2)}")
        print(f"è½¬ç½®: arr1.T =\n{arr1.T}")
        print(f"å±•å¹³: arr1.flatten() = {arr1.flatten()}")

    def numpy_indexing_slicing(self):
        """NumPyç´¢å¼•å’Œåˆ‡ç‰‡"""
        print("=" * 60)
        print("NumPy ç´¢å¼•å’Œåˆ‡ç‰‡")
        print("=" * 60)

        arr = np.array([[1, 2, 3, 4],
                        [5, 6, 7, 8],
                        [9, 10, 11, 12]])

        print(f"ç¤ºä¾‹æ•°ç»„:\n{arr}")
        print(f"å½¢çŠ¶: {arr.shape}")

        print("\n1. åŸºæœ¬ç´¢å¼•:")
        print(f"arr[0, 1] = {arr[0, 1]}")  # ç¬¬0è¡Œç¬¬1åˆ—
        print(f"arr[1] = {arr[1]}")  # ç¬¬1è¡Œ

        print("\n2. åˆ‡ç‰‡:")
        print(f"arr[0:2, 1:3] (å‰2è¡Œ, ç¬¬1-2åˆ—):\n{arr[0:2, 1:3]}")
        print(f"arr[:, 2] (æ‰€æœ‰è¡Œçš„ç¬¬2åˆ—): {arr[:, 2]}")

        print("\n3. å¸ƒå°”ç´¢å¼•:")
        bool_mask = arr > 5
        print(f"å¸ƒå°”æ©ç  (arr > 5):\n{bool_mask}")
        print(f"arr[arr > 5] = {arr[arr > 5]}")

    def numpy_linear_algebra(self):
        """NumPyçº¿æ€§ä»£æ•°"""
        print("=" * 60)
        print("NumPy çº¿æ€§ä»£æ•°æ“ä½œ")
        print("=" * 60)

        A = np.array([[1, 2], [3, 4]])
        B = np.array([[5, 6], [7, 8]])

        print(f"çŸ©é˜µ A:\n{A}")
        print(f"çŸ©é˜µ B:\n{B}")

        print("\n1. çŸ©é˜µè¿ç®—:")
        print(f"çŸ©é˜µä¹˜æ³• A @ B:\n{A @ B}")
        print(f"çŸ©é˜µä¹˜æ³• np.matmul(A, B):\n{np.matmul(A, B)}")

        print("\n2. çŸ©é˜µå±æ€§:")
        print(f"A çš„è¿¹: {np.trace(A)}")
        print(f"A çš„è¡Œåˆ—å¼: {np.linalg.det(A):.2f}")
        print(f"A çš„é€†çŸ©é˜µ:\n{np.linalg.inv(A)}")

        print("\n3. ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡:")
        eigenvalues, eigenvectors = np.linalg.eig(A)
        print(f"ç‰¹å¾å€¼: {eigenvalues}")
        print(f"ç‰¹å¾å‘é‡:\n{eigenvectors}")

    def numpy_statistics(self):
        """NumPyç»Ÿè®¡å‡½æ•°"""
        print("=" * 60)
        print("NumPy ç»Ÿè®¡å‡½æ•°")
        print("=" * 60)

        data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
        matrix = np.random.rand(3, 4) * 10

        print(f"ç¤ºä¾‹æ•°æ®: {data}")
        print(f"ç¤ºä¾‹çŸ©é˜µ:\n{matrix}")

        print("\n1. åŸºæœ¬ç»Ÿè®¡:")
        print(f"å¹³å‡å€¼: {np.mean(data):.2f}")
        print(f"ä¸­ä½æ•°: {np.median(data)}")
        print(f"æ ‡å‡†å·®: {np.std(data):.2f}")
        print(f"æ–¹å·®: {np.var(data):.2f}")

        print("\n2. çŸ©é˜µç»Ÿè®¡ (æ²¿è½´):")
        print(f"æ¯åˆ—çš„å¹³å‡å€¼: {np.mean(matrix, axis=0)}")
        print(f"æ¯è¡Œçš„æœ€å¤§å€¼: {np.max(matrix, axis=1)}")
        print(f"çŸ©é˜µæ€»å’Œ: {np.sum(matrix):.2f}")

        print("\n3. å…¶ä»–ç»Ÿè®¡:")
        print(f"ç™¾åˆ†ä½æ•° (25%, 50%, 75%): {np.percentile(data, [25, 50, 75])}")
        print(f"ç›¸å…³æ€§çŸ©é˜µ:\n{np.corrcoef(matrix)}")

    # ===== Scikit-learn å‡½æ•° =====
    def sklearn_data_loading(self):
        """Scikit-learnæ•°æ®åŠ è½½"""
        print("=" * 60)
        print("Scikit-learn æ•°æ®åŠ è½½")
        print("=" * 60)

        print("1. å†…ç½®æ•°æ®é›†:")

        # é¸¢å°¾èŠ±æ•°æ®é›†
        iris = datasets.load_iris()
        print(f"é¸¢å°¾èŠ±æ•°æ®é›†:")
        print(f"  ç‰¹å¾å½¢çŠ¶: {iris.data.shape}")
        print(f"  ç›®æ ‡å½¢çŠ¶: {iris.target.shape}")
        print(f"  ç‰¹å¾åç§°: {iris.feature_names}")
        print(f"  ç›®æ ‡åç§°: {iris.target_names}")
        print(f"  ç±»åˆ«æ•°é‡: {len(np.unique(iris.target))}")

        # æ‰‹å†™æ•°å­—æ•°æ®é›†
        digits = datasets.load_digits()
        print(f"\næ‰‹å†™æ•°å­—æ•°æ®é›†:")
        print(f"  ç‰¹å¾å½¢çŠ¶: {digits.data.shape}")
        print(f"  å›¾åƒå½¢çŠ¶: {digits.images[0].shape}")
        print(f"  ç±»åˆ«æ•°é‡: {len(np.unique(digits.target))}")

        print("\n2. ç”Ÿæˆæ•°æ®é›†:")
        X, y = datasets.make_classification(n_samples=100, n_features=4,
                                            n_informative=2, n_redundant=0,
                                            random_state=42)
        print(f"ç”Ÿæˆåˆ†ç±»æ•°æ®é›†:")
        print(f"  ç‰¹å¾å½¢çŠ¶: {X.shape}")
        print(f"  ç›®æ ‡å½¢çŠ¶: {y.shape}")

    def sklearn_preprocessing(self):
        """Scikit-learnæ•°æ®é¢„å¤„ç†"""
        print("=" * 60)
        print("Scikit-learn æ•°æ®é¢„å¤„ç†")
        print("=" * 60)

        # åˆ›å»ºç¤ºä¾‹æ•°æ®
        X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]], dtype=float)
        print(f"åŸå§‹æ•°æ®:\n{X}")

        print("\n1. æ ‡å‡†åŒ– (StandardScaler):")
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        print(f"æ ‡å‡†åŒ–å:\n{X_scaled}")
        print(f"å‡å€¼: {scaler.mean_}")
        print(f"æ ‡å‡†å·®: {scaler.scale_}")

        print("\n2. æ•°æ®åˆ†å‰²ç¤ºä¾‹:")
        X_train, X_test, y_train, y_test = train_test_split(
            X, [0, 1, 0, 1], test_size=0.25, random_state=42
        )
        print(f"è®­ç»ƒé›†å½¢çŠ¶: {X_train.shape}")
        print(f"æµ‹è¯•é›†å½¢çŠ¶: {X_test.shape}")

    def sklearn_train_test_split(self):
        """è®­ç»ƒæµ‹è¯•é›†åˆ†å‰²"""
        print("=" * 60)
        print("Scikit-learn è®­ç»ƒæµ‹è¯•é›†åˆ†å‰²")
        print("=" * 60)

        # åŠ è½½æ•°æ®
        iris = datasets.load_iris()
        X, y = iris.data, iris.target

        print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {X.shape}")
        print(f"ç›®æ ‡æ•°æ®å½¢çŠ¶: {y.shape}")

        print("\n1. åŸºæœ¬åˆ†å‰²:")
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )
        print(f"è®­ç»ƒé›†: {X_train.shape} ({(X_train.shape[0] / X.shape[0]) * 100:.1f}%)")
        print(f"æµ‹è¯•é›†: {X_test.shape} ({(X_test.shape[0] / X.shape[0]) * 100:.1f}%)")

        print("\n2. åˆ†å±‚åˆ†å‰² (ä¿æŒç±»åˆ«æ¯”ä¾‹):")
        X_train_strat, X_test_strat, y_train_strat, y_test_strat = train_test_split(
            X, y, test_size=0.3, stratify=y, random_state=42
        )

        print("åŸå§‹æ•°æ®ç±»åˆ«åˆ†å¸ƒ:")
        unique, counts = np.unique(y, return_counts=True)
        for cls, count in zip(unique, counts):
            print(f"  ç±»åˆ« {cls}: {count}æ ·æœ¬")

        print("åˆ†å±‚åˆ†å‰²åè®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒ:")
        unique_train, counts_train = np.unique(y_train_strat, return_counts=True)
        for cls, count in zip(unique_train, counts_train):
            print(f"  ç±»åˆ« {cls}: {count}æ ·æœ¬")

    def sklearn_classification(self):
        """Scikit-learnåˆ†ç±»ç®—æ³•"""
        print("=" * 60)
        print("Scikit-learn åˆ†ç±»ç®—æ³•")
        print("=" * 60)

        # åŠ è½½æ•°æ®
        iris = datasets.load_iris()
        X, y = iris.data, iris.target

        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )

        # æ ‡å‡†åŒ–
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        print("1. é€»è¾‘å›å½’åˆ†ç±»å™¨:")
        # åˆ›å»ºå’Œè®­ç»ƒæ¨¡å‹
        log_reg = LogisticRegression(random_state=42)
        log_reg.fit(X_train_scaled, y_train)

        # é¢„æµ‹
        y_pred = log_reg.predict(X_test_scaled)
        y_pred_proba = log_reg.predict_proba(X_test_scaled)

        # è¯„ä¼°
        accuracy = accuracy_score(y_test, y_pred)
        print(f"   å‡†ç¡®ç‡: {accuracy:.3f}")
        print(f"   é¢„æµ‹æ¦‚ç‡ç¤ºä¾‹:\n{y_pred_proba[:3]}")

        print("\n2. åˆ†ç±»æŠ¥å‘Š:")
        print(classification_report(y_test, y_pred, target_names=iris.target_names))

        print("3. æ¨¡å‹å‚æ•°:")
        print(f"   ç³»æ•°å½¢çŠ¶: {log_reg.coef_.shape}")
        print(f"   æˆªè·: {log_reg.intercept_}")

    def sklearn_clustering(self):
        """Scikit-learnèšç±»ç®—æ³•"""
        print("=" * 60)
        print("Scikit-learn èšç±»ç®—æ³•")
        print("=" * 60)

        # ç”Ÿæˆç¤ºä¾‹æ•°æ®
        X, y_true = datasets.make_blobs(n_samples=300, centers=3,
                                        cluster_std=0.60, random_state=42)

        print(f"ç”Ÿæˆæ•°æ®å½¢çŠ¶: {X.shape}")
        print(f"çœŸå®ç±»åˆ«æ•°: {len(np.unique(y_true))}")

        print("\n1. K-meansèšç±»:")
        # åº”ç”¨K-means
        kmeans = KMeans(n_clusters=3, random_state=42)
        y_pred = kmeans.fit_predict(X)

        print(f"   èšç±»ä¸­å¿ƒ:\n{kmeans.cluster_centers_}")
        print(f"   æƒ¯æ€§ (Within-cluster sum of squares): {kmeans.inertia_:.2f}")
        print(f"   è¿­ä»£æ¬¡æ•°: {kmeans.n_iter_}")

        print("\n2. èšç±»ç»“æœåˆ†æ:")
        from sklearn.metrics import adjusted_rand_score
        ari = adjusted_rand_score(y_true, y_pred)
        print(f"   è°ƒæ•´å…°å¾·æŒ‡æ•°: {ari:.3f}")

        # æ˜¾ç¤ºæ¯ä¸ªèšç±»çš„æ ·æœ¬æ•°
        unique, counts = np.unique(y_pred, return_counts=True)
        for cluster, count in zip(unique, counts):
            print(f"   èšç±» {cluster}: {count}ä¸ªæ ·æœ¬")


def main():
    """ä¸»å‡½æ•°"""
    helper = MLHelper()

    print("ğŸ¤– NumPy å’Œ Scikit-learn å­¦ä¹ åŠ©æ‰‹")
    print("=" * 50)

    while True:
        print("\nè¯·è¾“å…¥æ‚¨æƒ³äº†è§£çš„ä¸»é¢˜:")
        print("1. è¾“å…¥ 'list' æŸ¥çœ‹æ‰€æœ‰ä¸»é¢˜")
        print("2. è¾“å…¥ä¸»é¢˜åç§° (å¦‚: numpy_array_creation)")
        print("3. è¾“å…¥ 'quit' é€€å‡º")

        user_input = input("\nè¯·è¾“å…¥: ").strip().lower()

        if user_input == 'quit':
            print("å†è§ï¼")
            break
        elif user_input == 'list':
            helper.show_all_topics()
        elif user_input:
            helper.help(user_input)
        else:
            print("è¯·è¾“å…¥æœ‰æ•ˆå‘½ä»¤")


# ç¤ºä¾‹ç”¨æ³•
if __name__ == "__main__":
    # åˆ›å»ºåŠ©æ‰‹å®ä¾‹
    helper = MLHelper()

    # ç¤ºä¾‹ï¼šæŸ¥çœ‹æ‰€æœ‰ä¸»é¢˜
    print("ğŸ” æŸ¥çœ‹æ‰€æœ‰å¯ç”¨ä¸»é¢˜:")
    helper.show_all_topics()

    print("\n" + "=" * 70)
    print("ğŸ“š ç¤ºä¾‹è§£æ:")
    print("=" * 70)

    # è¿è¡Œä¸€äº›ç¤ºä¾‹
    helper.numpy_array_creation()
    helper.sklearn_classification()

    # äº¤äº’å¼æ¨¡å¼
    print("\n" + "=" * 70)
    print("ğŸ’¬ äº¤äº’æ¨¡å¼:")
    print("=" * 70)
    main()